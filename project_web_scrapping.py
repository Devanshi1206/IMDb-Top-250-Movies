# -*- coding: utf-8 -*-
"""Project - Web Scrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oGpkE-A34nGNR1ASwl6zYOs9j1_sDBic

## IMDb TOP 250 movies
"""

import pandas as pd
import bs4
from bs4 import BeautifulSoup
import csv
import requests

print('pandas version: {}'.format(pd.__version__))
print('bs4 version: {}'.format(bs4.__version__))
print('requests version: {}'.format(requests.__version__))
print('csv version: {}'.format(csv.__version__))

url = 'https://www.imdb.com/chart/top/'
uri = 'https://www.imdb.com'

headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}
response = requests.get(url, headers=headers)
print(response.status_code)

page_contents = response.text
len(page_contents)

soup = BeautifulSoup(response.text, 'html.parser')
print(soup.prettify())

scraped_movies = soup.find_all('td',class_="titleColumn")
movies = []
for x in scraped_movies:
  x = x.text.replace('\n','').strip()
  x = x[:x.find("(")]
  x = x[8:]
  movies.append(x)
print(movies)

scraped_rating = soup.find_all('td',class_='ratingColumn imdbRating')
ratings = []
for rating in scraped_rating:
  rating = rating.text.replace('\n','')
  ratings.append(rating)
print(ratings)

scraped_yr = soup.find_all('span',class_='secondaryInfo')
years = []
for year in scraped_yr:
  year = year.text.strip().replace('\n','')
  year = year.replace(',','')
  year = int(year[1:year.find(")")])
  if year > 1000 and year < 2025 :
     years.append(year)
print(years)

collection = soup.find_all('td',class_="titleColumn")
col_link = []
for col in collection:
  col_link.append(uri+col.find('a')["href"])
print(col_link)

data = pd.DataFrame()
data['Movie_Names'] = movies
data['Ratings'] = ratings
data['Released_Year'] = years
data['Movie_Link'] = col_link
data.head()

Votes=[]
Metascores=[]
Userreviews=[]
Criticreviews=[]
def data_from_mov(url_link):
    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}
    res = requests.get(url_link,headers=headers)
    htmlres = res.text
    #print(res.status_code)
    doc1=BeautifulSoup(htmlres,"html.parser")
    votes =  doc1.find_all('div',class_="sc-bde20123-3 bjjENQ")
    votes = votes[0]
    #print(votes.text)
    Votes.append(votes)
    metascore = doc1.find('span',class_="score-meta")
    if metascore is None:
      Metascores.append(0)
    else:
      #print(metascore.text)
      Metascores.append(int(metascore.text))
    reviews = doc1.find_all('span',class_="score")
    #print(reviews[0].text)
    Userreviews.append(reviews[0].text)
    #print(reviews[1].text)
    Criticreviews.append(reviews[1].text)


for x in col_link:
  data_from_mov(x)

data['Votes'] = Votes
data['Metascore'] = Metascores
data['Userreviews'] = Userreviews
data['Criticreviews'] = Criticreviews
data.head()
print(data.size)

data

data.to_csv("PopularMovies.csv")